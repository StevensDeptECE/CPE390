cache: fast memory used to remember frequently used data

principle of locality: we tend to read the same memory a lot
80-20

bigger is not necessarily better
       the bigger memory is, the slower it is
       transistors take time to switch from 0 to 1 or 1 to 0
       speed of your answer depends on how many transistors it goes through
AND(a,b)
OR(a,b)
XOR(a,b)
NOT(a)

CMOS - technology used to implement current circuits
N-channel MOSFETs have lower resistance than P-channel

NAND   NOT AND
NOR    NOT OR

A	B	AND	OR	NAND	NOR	XOR
0	0	0	0	1	1	0
0	1	0	1	1	0	1
1	0	0	1	1	0	1
1	1	1	1	0	0	0


ALU(add, sub, mul, div, sqrt, .....special)


switch(instr) {
case add: f1();
case sub: f2();
case mul: f3();
case special: special();
}

special() {
encryptAES256();
}


CISC	Complex Instruction Set Computer
RISC	Reduced Instruction Set Computer


memory is arranged in a rectangle (rows, cols)
latency is much higher if we go to a new place


Computer
	CPU	Central Processing Unit (4 cores)
	cache	fast memory to make it faster to re-read data
		L1 32k
		L2 2M
		L3 16M
	hit rate % of time cache is hit
	    problems with cache (you can't cache everything)

	registers - fastest on a computer
	   Intel 16 registers names are horrible

	   AARCH64  all integer registers are 64 bits
		X0	
		X1
		...
		X30
		X31	= 0 forget it

		w0	(low half of each x register)
		w1	
		..
		w30

		PC	Program Counter This is where your code is
		SP	Stack Pointer (where your data is for functions)
		LR	Link Register (Faster function calls)


